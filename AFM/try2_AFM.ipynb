{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(454, 454, 1, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prepare arrays:\n",
    "\n",
    "func_array = np.load(\"/home/gabridele/Desktop/irbio_folder/spreading_dynamics_clinical/derivatives/sub-10329/func/sub-10329_diff_wm_2vol_ts_1vol.npy\")\n",
    "func_array.shape\n",
    "func_array = np.expand_dims(func_array, axis=1)\n",
    "func_array.shape\n",
    "func_array = np.expand_dims(func_array, axis=2)\n",
    "func_array.shape\n",
    "\n",
    "conn_array = np.loadtxt(\"/home/gabridele/Desktop/irbio_folder/spreading_dynamics_clinical/derivatives/sub-10329/dwi/association_matrix_sub-10329.csv\",\n",
    "                 delimiter=\",\", dtype=float)\n",
    "conn_array.shape\n",
    "conn_array = np.expand_dims(conn_array, axis=2)\n",
    "conn_array.shape\n",
    "conn_array = np.expand_dims(conn_array, axis=3)\n",
    "conn_array.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabridele/miniconda3/envs/mrtrix3/lib/python3.9/site-packages/h5py/__init__.py:36: UserWarning: h5py is running against HDF5 1.14.3 when it was built against 1.12.1, this may cause problems\n",
      "  _warn((\"h5py is running against HDF5 {0} when it was built against {1}, \"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ttest_1samp\n",
    "import h5py\n",
    "\n",
    "# Assuming taskActMatrix and connMatrix are numpy arrays\n",
    "taskActMatrix = func_array\n",
    "connMatrix = conn_array # shape \n",
    "\n",
    "numTasks = taskActMatrix.shape[1]\n",
    "numRegions = taskActMatrix.shape[0]\n",
    "numConnStates = connMatrix.shape[2]\n",
    "numSubjs = connMatrix.shape[3]\n",
    "\n",
    "# Setup for prediction\n",
    "taskPredMatrix = np.zeros((numRegions, numTasks, numSubjs))\n",
    "taskPredRs = np.zeros((numTasks, numSubjs))\n",
    "taskActualMatrix = taskActMatrix\n",
    "regionNumList = np.arange(numRegions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Numba needs NumPy 1.21 or less",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mActflowToolbox\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mactflow\u001b[39;00m\n\u001b[1;32m      2\u001b[0m restFC_corr\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mzeros((numRegions,numRegions,numSubjs))\n\u001b[1;32m      3\u001b[0m scount\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/mrtrix3/lib/python3.9/site-packages/ActflowToolbox/__init__.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactflowcomp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m model_compare\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m connectivity_estimation\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dependencies\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#from . import infotransfermapping\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#from . import pipelines\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#from . import preprocessing\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mrtrix3/lib/python3.9/site-packages/ActflowToolbox/connectivity_estimation/__init__.py:8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpartial_corrconn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcombinedFC\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraphicalLassoCV\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/mrtrix3/lib/python3.9/site-packages/ActflowToolbox/connectivity_estimation/graphicalLassoCV.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stats\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m linalg\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgglasso\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproblem\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m glasso_problem \u001b[38;5;66;03m# (We began using the GGLasso package (https://gglasso.readthedocs.io/en/latest/) after sklearn's GraphicalLasso would not converge for all subjects for the tested hyperparameters)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcovariance\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m log_likelihood,empirical_covariance\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Kirsten Peterson, Sept. 2023\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Peterson, K. L., Sanchez-Romero, R., Mill, R. D., & Cole, M. W. (2023). Regularized partial correlation provides reliable functional connectivity estimates while correcting for widespread confounding. In bioRxiv (p. 2023.09.16.558065). https://doi.org/10.1101/2023.09.16.558065\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mrtrix3/lib/python3.9/site-packages/gglasso/problem.py:7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhelper\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbasic_linalg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m trp, adjacency_matrix, scale_array_by_diagonal\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhelper\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mext_admm_helper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_G\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msolver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01madmm_solver\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ADMM_MGL\n",
      "File \u001b[0;32m~/miniconda3/envs/mrtrix3/lib/python3.9/site-packages/gglasso/helper/basic_linalg.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mauthor: Fabian Schaipp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m njit\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m## general functions for the space G\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;129m@njit\u001b[39m()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrp\u001b[39m(X):   \n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# transposes for a block of matrices each single matrix\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# assumes that X is given in the form (K, p, p)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mrtrix3/lib/python3.9/site-packages/numba/__init__.py:200\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    199\u001b[0m _ensure_llvm()\n\u001b[0;32m--> 200\u001b[0m \u001b[43m_ensure_critical_deps\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;66;03m# we know llvmlite is working as the above tests passed, import it now as SVML\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;66;03m# needs to mutate runtime options (sets the `-vector-library`).\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mllvmlite\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mrtrix3/lib/python3.9/site-packages/numba/__init__.py:140\u001b[0m, in \u001b[0;36m_ensure_critical_deps\u001b[0;34m()\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumba needs NumPy 1.18 or greater\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m numpy_version \u001b[38;5;241m>\u001b[39m (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m21\u001b[39m):\n\u001b[0;32m--> 140\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumba needs NumPy 1.21 or less\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: Numba needs NumPy 1.21 or less"
     ]
    }
   ],
   "source": [
    "import ActflowToolbox as actflow\n",
    "restFC_corr=np.zeros((numRegions,numRegions,numSubjs))\n",
    "scount=0\n",
    "for subj in numSubjs:\n",
    "    restFC_corr[:,:,scount]=actflow.connectivity_estimation.corrcoefconn(connMatrix[:,:,scount])\n",
    "    scount += 1\n",
    "print(\"==Activity flow mapping results, correlation-based resting-state FC, 24 task conditions==\")\n",
    "actflowOutput_restFCCorr_bycond = actflow.actflowcomp.actflowtest(taskActMatrix, restFC_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for subjNum in range(numSubjs):\n",
    "    for taskNum in range(numTasks):\n",
    "\n",
    "        # Get this subject's activation pattern for this task\n",
    "        taskActVect = taskActMatrix[:, taskNum, subjNum]\n",
    "\n",
    "        for regionNum in range(numRegions):\n",
    "\n",
    "            # Hold out region whose activity is being predicted\n",
    "            otherRegions = np.delete(regionNumList, regionNum)\n",
    "\n",
    "            # Get this region's connectivity pattern\n",
    "            if numConnStates > 1:\n",
    "                stateFCVect = connMatrix[:, regionNum, taskNum, subjNum]\n",
    "            else:\n",
    "                # If using resting-state (or any single state) data\n",
    "                stateFCVect = connMatrix[:, regionNum, 0, subjNum]\n",
    "\n",
    "            # Calculate activity flow prediction\n",
    "            taskPredMatrix[regionNum, taskNum, subjNum] = np.sum(taskActVect[otherRegions] * stateFCVect[otherRegions])\n",
    "        # Normalize values (z-score)\n",
    "        taskPredMatrix[:, taskNum, subjNum] = (taskPredMatrix[:, taskNum, subjNum] - np.mean(taskPredMatrix[:, taskNum, subjNum])) / np.std(taskPredMatrix[:, taskNum, subjNum])\n",
    "        taskActualMatrix[:, taskNum, subjNum] = (taskActMatrix[:, taskNum, subjNum] - np.mean(taskActMatrix[:, taskNum, subjNum])) / np.std(taskActMatrix[:, taskNum, subjNum])\n",
    "\n",
    "        # Calculate predicted to actual similarity for this task\n",
    "        r = np.corrcoef(taskPredMatrix[:, taskNum, subjNum], taskActualMatrix[:, taskNum, subjNum])\n",
    "        taskPredRs[taskNum, subjNum] = r[0, 1]\n",
    "\n",
    "# Calculate average r, across-subject p-value\n",
    "r_bytask = np.tanh(np.mean(np.arctanh(taskPredRs), axis=1))\n",
    "p_bytask = np.ones(numTasks)\n",
    "for taskNum in range(numTasks):\n",
    "    _, p_bytask[taskNum] = ttest_1samp(np.arctanh(taskPredRs[taskNum, :]), 0)\n",
    "\n",
    "r_overall = np.tanh(np.mean(np.arctanh(taskPredRs)))  \n",
    "\n",
    "_, p_overall = ttest_1samp(np.mean(np.arctanh(taskPredRs), axis=0), 0) \n",
    "\n",
    "# By subject\n",
    "r_bysubj = taskPredRs\n",
    "t_overall = ttest_1samp(np.mean(np.arctanh(taskPredRs), axis=0), 0)[0]  \n",
    "\n",
    "# Calculate average-then-compare results\n",
    "r_avgfirst_bytask = np.zeros(numTasks)\n",
    "for taskNum in range(numTasks):\n",
    "    r_avgfirst_bytask[taskNum] = np.corrcoef(np.mean(taskPredMatrix[:, taskNum, :], axis=1), np.mean(taskActualMatrix[:, taskNum, :], axis=1))[0, 1]\n",
    "\n",
    "r_avgfirst_mean = np.tanh(np.mean(np.arctanh(r_avgfirst_bytask)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.004865986397817694\n"
     ]
    }
   ],
   "source": [
    "print(r_avgfirst_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00486599]]\n"
     ]
    }
   ],
   "source": [
    "print(taskPredRs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuroimg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
